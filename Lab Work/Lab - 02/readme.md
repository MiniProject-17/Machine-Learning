# Gradient Descent Optimization

This repository contains a simple implementation of the Gradient Descent algorithm. The included Jupyter notebook demonstrates how to optimize a function using gradient descent.

## Overview

- **Gradient Descent**: An iterative optimization algorithm used to minimize functions by updating parameters based on the gradient.

## Notebook

- **`Lab_02.ipynb`**: This notebook provides a step-by-step implementation of gradient descent, including the use of momentum for faster convergence.

## Usage

1. Open the notebook in Jupyter Notebook or any compatible environment.
2. Run the cells to see the implementation in action.

## License

This project is licensed under the MIT License.

